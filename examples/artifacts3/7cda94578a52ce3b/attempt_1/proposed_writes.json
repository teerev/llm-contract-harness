{
  "summary": "Created core simulation engine with World class and deterministic stepping, plus default ruleset implementing movement, energy, reproduction, and death while maintaining invariants and sorted agent ordering.",
  "writes": [
    {
      "base_sha256": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
      "content": "from __future__ import annotations\n\nimport random\nfrom typing import Dict, Tuple\n\nfrom .types import Agent, Position, SimConfig\n\n\ndef _wrap_pos(row: int, col: int, width: int, height: int) -> Position:\n    return Position(row % height, col % width)\n\n\ndef _move_target(pos: Position, direction: int, width: int, height: int) -> Position:\n    r, c = pos\n    if direction == 0:  # N\n        r -= 1\n    elif direction == 1:  # E\n        c += 1\n    elif direction == 2:  # S\n        r += 1\n    else:  # 3=W\n        c -= 1\n    return _wrap_pos(r, c, width, height)\n\n\ndef _adjacent_positions(pos: Position, width: int, height: int) -> Tuple[Position, Position, Position, Position]:\n    r, c = pos\n    return (\n        _wrap_pos(r - 1, c, width, height),\n        _wrap_pos(r, c + 1, width, height),\n        _wrap_pos(r + 1, c, width, height),\n        _wrap_pos(r, c - 1, width, height),\n    )\n\n\ndef default_ruleset(\n    agents: Dict[Position, Agent],\n    width: int,\n    height: int,\n    config: SimConfig,\n    rng: random.Random,\n) -> Tuple[Dict[Position, Agent], int, int, int]:\n    \"\"\"Default simulation rules.\n\n    Returns: (new_agents_dict, births_count, deaths_count, movements_count)\n\n    Notes:\n    - Builds a NEW agents dict from scratch each phase.\n    - Processes agents in sorted Position order.\n    - Grid wraps toroidally.\n    - No two agents may occupy the same cell.\n    \"\"\"\n\n    births = 0\n    deaths = 0\n    movements = 0\n\n    # Phase 1 \u2014 Age + Move + Energy update\n    old_items = sorted(agents.items(), key=lambda kv: kv[0])\n    new_agents: Dict[Position, Agent] = {}\n\n    for pos, agent in old_items:\n        aged = Agent(energy=agent.energy, age=agent.age + 1, direction=agent.direction)\n\n        target = _move_target(pos, aged.direction, width, height)\n\n        # Simplest correct approach per spec: only prevent collisions with already-placed agents.\n        if target not in new_agents:\n            final_pos = target\n            if final_pos != pos:\n                movements += 1\n        else:\n            final_pos = pos\n\n        # Randomize direction and apply energy changes\n        new_dir = rng.randint(0, 3)\n        new_energy = aged.energy - config.move_cost + config.energy_gain\n        updated = Agent(energy=new_energy, age=aged.age, direction=new_dir)\n\n        # Ensure we never lose an agent during movement; if collision at current cell too,\n        # fall back to keeping the first and forcing the second to stay is impossible.\n        # However, with the above rule (only checking new_agents), current cell should be free\n        # unless another agent already moved into it.\n        if final_pos in new_agents:\n            # Deterministic fallback: keep agent at original position if possible, else find any empty cell.\n            if pos not in new_agents:\n                final_pos = pos\n            else:\n                # Find first empty cell in row-major order (should be extremely rare).\n                for rr in range(height):\n                    for cc in range(width):\n                        p = Position(rr, cc)\n                        if p not in new_agents:\n                            final_pos = p\n                            break\n                    else:\n                        continue\n                    break\n\n        new_agents[final_pos] = updated\n\n    # Critical invariant for phase 1\n    if len(new_agents) != len(agents):\n        # As a last resort, rebuild by placing any missing agents into empty cells deterministically.\n        # This should not happen under normal conditions.\n        missing = len(agents) - len(new_agents)\n        if missing > 0:\n            empties = [Position(r, c) for r in range(height) for c in range(width) if Position(r, c) not in new_agents]\n            # Add placeholder agents? We cannot invent agents; instead, this indicates a logic error.\n            # Raise to surface the issue.\n            raise RuntimeError(\"Movement phase lost agents; invariant violated\")\n        else:\n            raise RuntimeError(\"Movement phase duplicated agents; invariant violated\")\n\n    # Phase 2 \u2014 Reproduction\n    # Iterate over a snapshot of positions to avoid iterating over newly added offspring.\n    for pos in sorted(list(new_agents.keys())):\n        parent = new_agents.get(pos)\n        if parent is None:\n            continue\n        if parent.energy >= config.reproduction_threshold:\n            candidates = [p for p in _adjacent_positions(pos, width, height) if p not in new_agents]\n            if candidates:\n                child_pos = rng.choice(candidates)\n                child = Agent(energy=config.reproduction_cost, age=0, direction=rng.randint(0, 3))\n                new_agents[child_pos] = child\n                new_agents[pos] = Agent(\n                    energy=parent.energy - config.reproduction_cost,\n                    age=parent.age,\n                    direction=parent.direction,\n                )\n                births += 1\n\n    # Phase 3 \u2014 Death\n    survivors: Dict[Position, Agent] = {}\n    for pos, agent in sorted(new_agents.items(), key=lambda kv: kv[0]):\n        if agent.energy <= 0 or agent.age > config.max_age:\n            deaths += 1\n        else:\n            survivors[pos] = agent\n\n    # Final invariant check\n    population_before = len(agents)\n    population_after = len(survivors)\n    if population_before + births - deaths != population_after:\n        raise RuntimeError(\n            \"Population invariant violated: before + births - deaths != after \"\n            f\"({population_before} + {births} - {deaths} != {population_after})\"\n        )\n\n    return survivors, births, deaths, movements\n",
      "path": "lifesim/rules.py"
    },
    {
      "base_sha256": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
      "content": "from __future__ import annotations\n\nimport random\nfrom typing import Dict, Optional\n\nfrom .types import Agent, Position, SimConfig, StepResult, WorldState\n\n\ndef create_world(config: SimConfig) -> \"World\":\n    rng = random.Random(config.seed)\n    agents: Dict[Position, Agent] = {}\n\n    for row in range(config.height):\n        for col in range(config.width):\n            if rng.random() < config.initial_density:\n                pos = Position(row, col)\n                agents[pos] = Agent(energy=config.initial_energy, age=0, direction=rng.randint(0, 3))\n\n    # Start is always Position(0,0) (step_number=0)\n    state = WorldState(\n        width=config.width,\n        height=config.height,\n        step_number=0,\n        seed=config.seed,\n        agents=tuple(sorted(agents.items(), key=lambda kv: kv[0])),\n    )\n    return World(config=config, state=state)\n\n\nclass World:\n    def __init__(self, config: SimConfig, state: WorldState, ruleset=None):\n        self.config = config\n        self._step_number = state.step_number\n        self._agents: Dict[Position, Agent] = dict(state.agents)\n\n        if ruleset is None:\n            from .rules import default_ruleset\n\n            self._ruleset = default_ruleset\n        else:\n            self._ruleset = ruleset\n\n    def step(self) -> StepResult:\n        # Deterministic per-step RNG for resumability\n        rng = random.Random(self.config.seed * 6364136223846793005 + self._step_number)\n\n        new_agents, births, deaths, movements = self._ruleset(\n            self._agents,\n            self.config.width,\n            self.config.height,\n            self.config,\n            rng,\n        )\n\n        self._step_number += 1\n        self._agents = new_agents\n\n        state = WorldState(\n            width=self.config.width,\n            height=self.config.height,\n            step_number=self._step_number,\n            seed=self.config.seed,\n            agents=tuple(sorted(self._agents.items(), key=lambda kv: kv[0])),\n        )\n\n        return StepResult(world=state, births=births, deaths=deaths, movements=movements)\n\n    def get_state(self) -> WorldState:\n        return WorldState(\n            width=self.config.width,\n            height=self.config.height,\n            step_number=self._step_number,\n            seed=self.config.seed,\n            agents=tuple(sorted(self._agents.items(), key=lambda kv: kv[0])),\n        )\n",
      "path": "lifesim/world.py"
    }
  ]
}
