# Factory & Planner Nondeterminism Audit

Strict analysis of determinism claims vs reality. Every source of
nondeterminism is classified and its impact on reproducibility assessed.

---

## The Claims

The system makes the following determinism claims:

- README.md line 3: **"A deterministic contract layer"**
- README.md line 8: **"deterministic harness (SE → TR → PO)"**
- README.md line 10: **"LLM non-determinism cannot bypass deterministic enforcement"**
- INVARIANTS.md L4: **"LLM non-determinism does not violate deterministic invariants"**
- `run.py:64` comment: **"Deterministic run_id"**
- `compiler.py:48` comment: **"SHA-256 over spec + template + model + reasoning effort"** (claimed deterministic)

The audit evaluates these claims against the code.

---

## 1. Truly Deterministic Components

These components produce identical output given identical input, with no
hidden state, no filesystem iteration, no time dependence, and no
randomness. The determinism claim is accurate.

### D1: `_validate_relative_path` — path validation

**Location:** `factory/schemas.py:28-52`

Pure function. String in → string out (or exception). No filesystem
access, no iteration, no time. Deterministic.

### D2: `canonical_json_bytes` — JSON canonicalization

**Location:** `factory/util.py:50-52`

```python
json.dumps(obj, sort_keys=True, separators=(",", ":")).encode("utf-8")
```

Python's `json.dumps` with `sort_keys=True` produces a deterministic
byte string for any JSON-serializable input. No hidden state.
Deterministic.

### D3: `compute_run_id` — run ID derivation

**Location:** `factory/util.py:55-61`

`SHA-256(canonical_json(work_order) + "\n" + baseline_commit)[:16]`.
Composition of D2 + hashlib. Deterministic given identical work order
dict and baseline commit string.

### D4: `_compute_compile_hash` — compile hash derivation

**Location:** `planner/compiler.py:42-57`

`SHA-256(spec_bytes + "\n" + template_bytes + "\n" + model + "\n" + reasoning_effort)[:16]`.
Pure hash of byte inputs. Deterministic.

### D5: `sha256_file` / `sha256_bytes` — file hashing

**Location:** `factory/util.py:36-47`

SHA-256 of file bytes (or empty bytes for missing files). Deterministic
given identical file content. The hash of a missing file is the hash of
`b""` — this is a fixed constant, not dependent on filesystem state beyond
file existence.

### D6: TR scope / hash checks

**Location:** `factory/nodes_tr.py:98-164`

All TR validation steps (duplicate check, scope check, path safety check,
base-hash check) are pure functions of the proposal content and the
work order's `allowed_files`. Given the same proposal and the same
filesystem state, they produce the same verdict. Deterministic.

### D7: Pydantic schema validation

**Location:** `factory/schemas.py` (all validators)

Pydantic validation is deterministic for the same input dict. Size limits,
path validation, stage enumeration — all pure. Deterministic.

---

## 2. Probabilistically Deterministic but Claimed as Strict

These components are nondeterministic in general but are *likely* to
produce the same output for the same logical input in practice. The system
treats them as deterministic without acknowledgment of the gap.

### P1: LLM calls (both planner and factory)

**Location:** `factory/llm.py:36-52` (Chat Completions),
`planner/openai_client.py:85-150` (Responses API)

**The claim:** L4 in INVARIANTS.md says "LLM non-determinism does not
violate deterministic invariants." This is true — the LLM output is
validated before side effects. But the system uses LLM output to determine
the *content* of files written to the repo. Two runs with the same input
can produce different file content, different tree hashes, and different
verdicts.

**The factory uses `temperature=0` by default.** This reduces but does not
eliminate nondeterminism. OpenAI's documentation states that `temperature=0`
is not a guarantee of identical output: model updates, infrastructure
routing, and floating-point nondeterminism in GPU batching can all cause
different outputs for identical prompts. The `seed` parameter (which does
provide a best-effort determinism guarantee from OpenAI) is not used.

**The planner does not use temperature at all.** The Responses API call
(`openai_client.py:150-156`) passes `reasoning.effort` but no
`temperature` parameter. The model uses its default temperature (which for
reasoning models is typically not zero).

**Impact:** The `repo_tree_hash_after` in `run_summary.json` is
nondeterministic. The same work order on the same baseline can produce
different code. This is expected (the system is designed around this), but
the README's "deterministic harness" language is misleading — the harness's
*enforcement* is deterministic, but the *outcome* is not.

**Reproducibility impact:** High. Two runs of the same work order are not
guaranteed to produce the same result. The compile hash and run_id are
deterministic, but the code content, the tree hash, and the pass/fail
verdict are all nondeterministic.

### P2: LLM response to retry feedback

**Location:** `factory/nodes_se.py:121-132` (failure brief injection)

On retry, the SE prompt includes the failure brief from the previous
attempt. The LLM sees a different prompt on each attempt (original →
original + failure_brief_1 → original + failure_brief_2). This is
intentional — the system expects the LLM to correct its mistakes. But
it means the retry sequence is path-dependent: the outcome of attempt 2
depends on the specific failure of attempt 1, which is LLM-nondeterministic.

**Impact:** The attempt artifacts (which failure occurred, what the
retry prompt said, what the LLM produced on retry) are all
nondeterministic. The `total_attempts` count and per-attempt records in
`run_summary.json` are not reproducible.

---

## 3. Nondeterministic and Undocumented

These components introduce nondeterminism that is not acknowledged in the
system's documentation or invariants.

### N1: `time.time()` in compile summary

**Location:** `planner/compiler.py:385, 393-394`

```python
"start_timestamp": ts_start,
"end_timestamp": time.time(),
"duration_seconds": round(time.time() - ts_start, 3),
```

The `compile_summary.json` artifact contains wall-clock timestamps and
a computed duration. These are different on every run, even with identical
inputs. The summary artifact is not byte-reproducible across runs.

**Impact on reproducibility:** Low for correctness (timestamps are
metadata, not inputs to any computation). But if anyone diffs two
`compile_summary.json` files expecting identical content from identical
inputs, they will always differ.

**Documented?** No. The compile hash is documented as deterministic, but
the summary artifact's nondeterminism is not mentioned.

### N2: `time.monotonic()` in `run_command` durations

**Location:** `factory/util.py:129, 138, 152, 172, 192`

```python
start = time.monotonic()
# ...
duration_seconds=round(duration, 3),
```

Every `CmdResult` includes `duration_seconds`, which depends on wall-clock
execution time. This value flows into `verify_result.json` and
`acceptance_result.json` artifacts, and then into `run_summary.json` via
the attempt records.

**Impact on reproducibility:** Low. The `duration_seconds` value is
different on every run. It does not affect any decision (the factory
never uses duration to decide pass/fail). But the artifact files are
non-reproducible.

### N3: `os.walk` iteration order in `_build_repo_file_listing`

**Location:** `planner/compiler.py:85-96`

```python
def _build_repo_file_listing(repo_path: str) -> set[str]:
    result: set[str] = set()
    for root, dirs, files in os.walk(repo_path):
        dirs[:] = [d for d in dirs if d not in _SKIP_DIRS]
        for f in files:
            # ...
            result.add(...)
    return result
```

`os.walk` returns directory entries in filesystem-dependent order. On
ext4 (Linux), directory entries are stored in hash order, which can vary
across filesystem instances. On HFS+/APFS (macOS), entries are stored
in B-tree order (typically alphabetical).

The result is a `set[str]`, which is iteration-order-independent for
set membership tests. **But:** `dirs[:] = [d for d in dirs if d not in _SKIP_DIRS]`
mutates the `dirs` list, which controls `os.walk`'s traversal order.
If `dirs` comes back in different orders on different filesystems, the
*pruning* is the same (same set of skip dirs), but the *traversal order*
differs. Since the result is a set, the final output is the same regardless
of traversal order.

**Impact on reproducibility:** None for the final file listing. But the
*order* in which files are discovered (and therefore the order in which
context-budget truncation is applied in a hypothetical extension) could
matter.

**Verdict:** Sound. The set return type absorbs the nondeterminism.

### N4: `os.path.abspath` in compile summary

**Location:** `planner/compiler.py:379, 380, 390, 391`

```python
"spec_path": os.path.abspath(spec_path),
"template_path": os.path.abspath(template_path),
"outdir": os.path.abspath(result.outdir),
"artifacts_dir": os.path.abspath(result.artifacts_dir),
```

Absolute paths in the summary depend on the current working directory and
the host's filesystem layout. Running the same command from a different
directory or on a different machine produces different paths.

**Impact on reproducibility:** Low. These are metadata for human
consumption, not inputs to any computation. But the artifact is
non-reproducible across machines.

**Documented?** No.

### N5: `os.path.realpath` for `repo_root` in run summary

**Location:** `factory/run.py:23, 77`

```python
repo_root = os.path.realpath(args.repo)
# ...
"repo_root": repo_root,
```

Same issue as N4: the resolved path depends on the host's filesystem.
It's recorded in `run_config` inside `run_summary.json`.

**Impact on reproducibility:** Low. Metadata only.

### N6: Verify and acceptance command execution is environment-dependent

**Location:** `factory/nodes_po.py:90-199`, `factory/util.py:118-193`

Commands are executed via `subprocess.run(shell=False)` with `cwd=repo_root`.
The command's behavior depends on:

- **`PATH`:** Which `python`, `bash`, `pip` is found depends on the
  operator's `PATH`. Different virtual environments, different Python
  versions, different pip versions.

- **Python version:** `python -m compileall -q .` (the verify fallback)
  behavior varies across Python versions. New syntax accepted in 3.12 is
  rejected in 3.10. `python -m pytest -q` output format changes across
  pytest versions. The test suite run by verify is not pinned.

- **Installed packages:** `python -m pip --version` (verify fallback)
  depends on which pip is installed. Acceptance commands like
  `python -c "from mypackage import X"` depend on what's on `PYTHONPATH`.

- **Network access during verify/acceptance:** If `scripts/verify.sh`
  runs `pip install` or `pytest` fetches fixtures from the network, the
  result depends on network availability and package registry state.
  There is no network restriction on subprocess execution. The verify
  and acceptance commands can make arbitrary network calls. A `pytest`
  that passes on Monday can fail on Tuesday because a dependency was
  yanked from PyPI.

- **Locale and encoding:** `subprocess.run(capture_output=True)` captures
  bytes. Commands that output locale-dependent text (date formats, error
  messages in non-English locales) produce different output.

- **Filesystem case sensitivity:** macOS (APFS) is case-insensitive by
  default; Linux (ext4) is case-sensitive. `import mypackage` may resolve
  differently.

**Impact on reproducibility:** High. The pass/fail verdict depends on the
host environment. The same code can PASS on the developer's machine and
FAIL in CI (or vice versa). This is inherent to running unsandboxed
commands, but the system does not record the environment in a way that
enables diagnosis.

**Documented?** ARCHITECTURE.md §6 says the factory is "designed for Python
projects" and notes `pytest` as the default verifier. It does not document
environment dependence as a reproducibility risk.

**Partially mitigated (M-18):** The `defaults_snapshot` in `run_summary.json`
records factory configuration defaults. But it does **not** record Python
version, platform, `PATH`, installed packages, or virtual environment state.
The compile summary records `model` and `reasoning_effort` but not the
host environment.

### N7: `WO-*.json` key order is insertion-dependent

**Location:** `planner/io.py:74`

```python
content = json.dumps(wo, indent=2, sort_keys=False) + "\n"
```

Work order JSON files are written with `sort_keys=False`. The key order
in the output file depends on the insertion order of the work order dict,
which comes from the LLM's JSON output as parsed and normalized by the
planner. If the LLM produces keys in a different order on a retry, the
emitted `WO-*.json` file has different byte content.

Compare with `save_json` in `factory/util.py:89`:
```python
content = json.dumps(data, indent=2, sort_keys=True) + "\n"
```
which uses `sort_keys=True`. And `write_json_artifact` in `planner/io.py:89`:
```python
content = json.dumps(data, indent=2, sort_keys=True) + "\n"
```
which also uses `sort_keys=True`.

The inconsistency: factory artifacts and planner diagnostic artifacts use
`sort_keys=True` (deterministic byte order), but the planner's output
work order files and manifest use `sort_keys=False` (LLM-dependent order).

**Impact on reproducibility:** Medium. Two planner runs with the same spec
can produce `WO-*.json` files that are semantically identical but byte-
different. The `WORK_ORDERS_MANIFEST.json` (line 80, also `sort_keys=False`)
has the same issue. Any tool that diffs or checksums these files will see
differences that are not semantic.

**Documented?** No. The compile hash is deterministic (based on inputs),
but the output files are not byte-reproducible even with identical compile
inputs, because LLM output order varies.

### N8: `frozenset` repr nondeterminism in `defaults_snapshot`

**Location:** `factory/run.py:79-92`, `planner/compiler.py:395-412`

The `defaults_snapshot` dicts in `run_summary.json` and
`compile_summary.json` are serialized with `save_json` / `write_json_artifact`
(both use `sort_keys=True`). The values are Python primitives (int, float,
str), which serialize deterministically. However, any `frozenset` or `set`
values would serialize nondeterministically — `json.dumps` cannot serialize
sets, so this issue is currently avoided because sets are not included in
the snapshot dicts (only their lengths or string representations would be).

**Impact:** None currently. But if anyone adds a `frozenset`-typed default
to the snapshot, it would crash (`TypeError: Object of type frozenset is
not JSON serializable`). This is a latent issue, not an active one.

### N9: `tempfile.mkstemp` temp-file naming

**Location:** `factory/nodes_tr.py:30`, `factory/util.py:92`,
`planner/io.py:15`

`tempfile.mkstemp` generates a random suffix for the temp file name. This
is invisible in normal operation (the temp file is renamed or deleted), but
if the process crashes between `mkstemp` and `os.replace`, the temp file
persists with a random name. Different crashes leave different temp file
names, which would be visible in `git status` output and could affect
`is_clean` checks.

**Impact on reproducibility:** None in the normal case. Cosmetic in crash
recovery (different temp file names).

---

## 4. Summary: Claim vs Reality

| Claim | Location | Verdict |
|-------|----------|---------|
| "Deterministic contract layer" | README.md:3 | **Partially true.** The *enforcement* (validation, scope, hashes) is deterministic. The *outcome* (what code is produced, whether it passes tests) is nondeterministic because the LLM is nondeterministic. The word "deterministic" in the README describes the enforcement layer, not the end-to-end system, but the distinction is not made explicit. |
| "Deterministic harness" | README.md:8 | **Partially true.** Same as above. The harness's *checks* are deterministic. The harness's *inputs* (LLM output) and *side effects* (file content, command results) are not. |
| "LLM non-determinism cannot bypass deterministic enforcement" | README.md:10, INVARIANTS.md L4 | **True.** This is the precise claim and it holds. No matter what the LLM outputs, the scope checks, hash checks, and path validation produce the same verdict for the same LLM output. The LLM cannot bypass these checks by being nondeterministic. |
| "Deterministic run_id" | `run.py:64` | **True.** `run_id` is a pure hash of the work order content and baseline commit. Identical inputs produce identical `run_id`. |
| "Deterministic compile hash" | `compiler.py:48` | **True.** Pure hash of spec + template + model + reasoning. |
| Artifact reproducibility (implicit) | All artifact writes | **False.** `compile_summary.json`, `run_summary.json`, `verify_result.json`, `acceptance_result.json` all contain timestamps, durations, and absolute paths that differ across runs. `WO-*.json` files use `sort_keys=False` so byte order depends on LLM output order. No artifact is byte-reproducible across runs, even for identical inputs. |

### The Real Determinism Boundary

The system has a clean determinism boundary, but the documentation blurs it:

**Deterministic (given same inputs):**
- Run ID and compile hash computation
- Schema validation (accept/reject)
- Path validation (accept/reject)
- Scope checking (accept/reject)
- Base-hash checking (accept/reject)
- Rollback operations
- Precondition / postcondition gate logic

**Nondeterministic:**
- LLM output content (both planner and factory)
- Command execution results (environment-dependent)
- Timestamps and durations in artifacts
- Key order in `WO-*.json` files
- Absolute paths in artifact metadata
- Whether a run PASSes or FAILs (depends on LLM + environment)
- What code ends up in the repo (depends on LLM)
- The tree hash (depends on LLM)

The correct statement is: **"The enforcement layer is deterministic; the
execution layer is nondeterministic; the enforcement layer's verdicts are
determined solely by the execution layer's outputs, not by hidden state."**
That is a meaningful and correct guarantee. "Deterministic contract layer"
is a reasonable shorthand. "Deterministic harness" is slightly misleading.
