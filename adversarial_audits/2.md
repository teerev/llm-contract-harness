# Factory Transactional Safety Audit

Pessimistic analysis of the factory execution path under the assumption
that the process can be killed (`SIGKILL`, OOM-killer, power loss) at any
instruction boundary. Based on direct inspection of all production code
in `factory/`.

---

## 1. Points Where the Repo May Be Left Modified

The product repo (`--repo`) is the only stateful resource with a
durability guarantee (it's a git repo on disk). The artifact output
directory (`--out`) is write-only diagnostic storage. The analysis below
focuses on repo state, but also covers artifact-directory corruption
where it affects recoverability.

### Window W1: Between first `_atomic_write` and last `_atomic_write` in TR

**Location:** `factory/nodes_tr.py::tr_node`, lines 169-181

```python
for w in proposal.writes:
    norm = normalize_path(w.path)
    abs_path = os.path.join(repo_root, norm)
    try:
        _atomic_write(abs_path, w.content)     # ← each write is atomic
    except Exception as exc:
        return _tr_fail(...)
```

**Unsafe window:** A proposal with N files writes them sequentially. If the
process is killed after file K is written but before file K+1 is written,
the repo contains a mix: files 1..K have new content, files K+1..N have
old content. Each individual `_atomic_write` is crash-safe (temp + fsync +
os.replace), so no single file can be half-written. But the **batch** is
not transactional.

**Worst case:** For a 3-file proposal, a kill between file 1 and file 2
leaves one file updated and two stale. The repo is in a state that never
existed in any correct execution — it has partial writes from the proposal
but no rollback was performed.

**Does this violate atomicity guarantees?** Yes. The system claims rollback
to baseline on failure, but a SIGKILL during TR's write loop bypasses the
finalize node entirely. No rollback runs. The repo is left dirty.

**Mitigating factor:** The emergency handler in `run.py:126` catches
`BaseException` (including `KeyboardInterrupt`) and attempts rollback. But
SIGKILL, OOM-kill, and power loss are not catchable by any Python handler.

### Window W2: Between TR writes and finalize rollback

**Location:** `factory/graph.py::_finalize_node`, lines 129-130

```python
if verdict == "FAIL":
    rollback(repo_root, baseline)
```

**Unsafe window:** If PO (verify/acceptance) fails and finalize begins
execution, there is a window between entering `_finalize_node` and the
`rollback()` call where the repo still contains TR's writes. A kill here
leaves the repo modified. This window includes: `os.makedirs` (line 95),
failure-brief determination (line 100), proposal-path check (lines
103-105), failure-brief artifact write (line 110), attempt-record
construction (lines 113-122), and the attempts-list append (lines
124-125) — all before line 130 where rollback actually runs.

**Worst case:** Identical to W1 — repo has writes applied, no rollback.
The `run_summary.json` may or may not exist (if finalize was killed before
the emergency handler in `run.py` could fire, no summary is written either).

**Does this violate atomicity guarantees?** Yes. Same reasoning as W1.

### Window W3: Between `rollback()` `git reset --hard` and `git clean -fdx`

**Location:** `factory/workspace.py::rollback`, lines 95-106

```python
res = _git(["reset", "--hard", baseline_commit], cwd=repo_root)
# ← kill here
res = _git(["clean", "-fdx"], cwd=repo_root)
```

**Unsafe window:** `rollback()` is a two-step operation. If the process is
killed after `git reset --hard` succeeds but before `git clean -fdx` runs,
the repo's tracked files are restored to baseline but **untracked files
created by the proposal** (new files that didn't exist at baseline) are
still present on disk. `git reset --hard` only affects tracked files.

**Worst case:** New files created by TR (files whose `base_sha256` was the
empty-bytes hash, meaning they didn't exist before) survive the partial
rollback. The preflight `is_clean` check on the next run will detect
these untracked files and refuse to proceed (`run.py:42-48`), so they
cannot silently corrupt a subsequent run. But manual intervention is
required (`git clean -fdx`).

**Does this violate atomicity guarantees?** Partially. Tracked files are
correctly restored; untracked files leak. The preflight catch prevents
silent corruption, so this is a liveness issue (blocks the next run) rather
than a correctness issue.

### Window W4: PASS path — between TR writes and `get_tree_hash`

**Location:** `factory/graph.py::_finalize_node`, lines 131-135

```python
else:
    touched = list(state.get("touched_files") or [])
    repo_tree_hash_after = get_tree_hash(repo_root, touched_files=touched or None)
```

**Unsafe window:** On the PASS path, finalize does NOT rollback — it stages
files via `git add` and computes `git write-tree`. If the process is killed
after `git add` but before `run_summary.json` is written (line 219 of
`run.py`), the repo has the correct content on disk and files are staged in
the git index, but no summary artifact records the success. The
`run_work_orders.sh` batch script would see a non-zero exit code and
stop.

**Worst case:** Successful writes are on disk and staged, but no machine-
readable record exists. A re-run would produce a different `run_id` if the
baseline commit has changed (because `run_work_orders.sh` committed between
WOs), or the same `run_id` if baseline hasn't changed — in which case
artifacts are silently overwritten (see `1.md` issue 5).

**Does this violate atomicity guarantees?** Yes, but in the opposite
direction from W1-W3: the *work* is done, but the *record* is missing.
The repo is in a correct state; only observability is broken.

### Window W5: `se_prompt.txt` written non-atomically

**Location:** `factory/nodes_se.py`, lines 227-229

```python
prompt_path = os.path.join(attempt_dir, ARTIFACT_SE_PROMPT)
with open(prompt_path, "w", encoding="utf-8") as fh:
    fh.write(prompt)
```

**Unsafe window:** This is a bare `open` + `write` without fsync or atomic
replace. A kill during the write leaves a truncated `se_prompt.txt` on
disk. This is an artifact file (not in the product repo), so it cannot
affect repo state.

**Worst case:** Truncated diagnostic artifact. Misleading for post-mortem
analysis but no correctness impact.

**Does this violate atomicity guarantees?** No. This is a diagnostic
artifact, not a contract artifact. The prompt is not re-read by any
subsequent step.

### Window W6: `run_command` stdout/stderr files written non-atomically

**Location:** `factory/util.py::run_command`, lines 140-143, 159-162,
181-184

```python
with open(stdout_path, "wb") as fh:
    fh.write(proc.stdout)
with open(stderr_path, "wb") as fh:
    fh.write(proc.stderr)
```

**Unsafe window:** Same as W5 — bare `open` + `write` for diagnostic
output capture. A kill between the stdout write and the stderr write
leaves stdout present but stderr missing (or vice versa).

**Worst case:** Truncated or missing diagnostic files. No correctness
impact.

**Does this violate atomicity guarantees?** No. Diagnostic artifacts only.

---

## 2. Is There a Persistent "Transaction in Progress" Marker?

**No.**

There is no lock file, no journal, no `.in_progress` marker, and no WAL
(write-ahead log) written at any point during factory execution.

The closest thing to a persistent marker is:

- The `work_order.json` artifact written at `run.py:70` before the graph
  starts. This proves a run was *initiated* but does not indicate whether
  it is *in progress* or *completed*. If the process is killed after this
  write but before `run_summary.json` is written, the artifact directory
  contains `work_order.json` but no summary — the run is invisible to
  tooling that reads `run_summary.json`.

- The `se_prompt.txt` and `failure_brief.json` write-ahead artifacts in
  `nodes_se.py` (lines 228, 246, 270). These are labeled "write-ahead:
  persist now in case process is killed before finalize runs" in comments.
  They serve as crash-recovery *evidence* but are not read by any recovery
  logic — no code path inspects them to determine whether a transaction
  was interrupted.

**Summary:** The system produces artifacts during execution that could
theoretically be used for crash detection, but no code consumes them for
that purpose.

---

## 3. Does the System Detect or Recover from Partial Execution on Startup?

**No.**

The preflight checks in `run.py:38-57` check:

1. Is the path a git repo? (`is_git_repo`)
2. Is the working tree clean? (`is_clean`)
3. Is the output dir outside the repo? (path prefix check)

Check #2 (`is_clean`) is the only one relevant to crash recovery. If a
previous run was killed during W1 or W2 (repo has uncommitted
modifications), `is_clean` returns `False` and the factory refuses to
start with the error message: *"The working tree must be clean (no staged,
unstaged, or untracked changes)."*

**This is a detection but not a recovery.** The system identifies that
something is wrong but does not:

- Determine *why* the repo is dirty (crash? user edits? previous run?)
- Inspect the artifact directory for evidence of an interrupted run
- Offer or perform automatic rollback
- Identify which baseline commit to roll back to

The user must manually run `git reset --hard <commit> && git clean -fdx`.
The emergency handler in `run.py:142-148` prints a remediation command
when rollback fails, and `run_summary.json` (if written, M-09) includes
a `remediation` field — but these only help if the process survived long
enough to write them. A SIGKILL leaves no remediation guidance.

**The `baseline_commit` is ephemeral.** It is computed at runtime
(`run.py:60`) and stored only in the in-memory `initial_state` dict. If
the process is killed before `run_summary.json` is written, the baseline
commit is lost. The user must determine it from git reflog or by
inspecting the `work_order.json` artifact (which does not contain the
baseline commit — it contains the work order content only).

---

## 4. Are Rollback Operations Idempotent?

**Partially.**

### `git reset --hard <baseline_commit>`

**Idempotent?** Yes. Running `git reset --hard <commit>` when HEAD is
already at `<commit>` is a no-op. Running it when HEAD is elsewhere moves
HEAD and the working tree to the target. Running it twice produces the
same result.

### `git clean -fdx`

**Idempotent?** Yes. Running `git clean -fdx` on a clean working tree
(no untracked files) is a no-op. Running it when untracked files exist
removes them. Running it twice produces the same result.

### `rollback()` as a whole

**Idempotent?** Yes, with a caveat. The two-step sequence (`reset --hard`
then `clean -fdx`) is idempotent because both steps are individually
idempotent. However, **rollback is not atomic** (see W3 above). If the
first step succeeds and the second fails (or the process is killed between
them), re-running `rollback()` will correctly complete the cleanup because
`git reset --hard` is a no-op the second time and `git clean -fdx` then
removes the leftover untracked files.

### `rollback()` when called with the wrong baseline

**Not safe.** If the `baseline_commit` value is wrong (e.g., corrupted
state, or a different run's baseline), `git reset --hard` moves HEAD to
the wrong commit. This is not a plausible scenario under normal operation
(baseline is computed once and stored in memory), but it is worth noting
that rollback does not validate that the target commit is the correct
baseline — it trusts the caller.

---

## 5. Summary: Unsafe Windows

| ID | Location | Trigger | Repo left modified? | Recovery available? | Violates atomicity? | Severity |
|----|----------|---------|---------------------|---------------------|---------------------|----------|
| W1 | `nodes_tr.py:169-181` | Kill during multi-file write loop | Yes — partial writes (K of N files) | Manual: `git reset --hard && git clean -fdx` | **Yes** | High |
| W2 | `graph.py:86-130` | Kill between PO failure and finalize rollback | Yes — all writes applied, no rollback | Manual: same | **Yes** | High |
| W3 | `workspace.py:95-106` | Kill between `reset --hard` and `clean -fdx` | Partially — tracked files OK, untracked files leak | Preflight blocks next run; manual `git clean -fdx` | Partial | Medium |
| W4 | `graph.py:131-135` + `run.py:218-219` | Kill after PASS writes, before summary | No — repo correct, but no summary artifact | Re-run produces correct result; artifacts may collide | No (repo OK) | Low |
| W5 | `nodes_se.py:227-229` | Kill during prompt write | No — artifact only | None needed | No | Cosmetic |
| W6 | `util.py:140-143` | Kill during stdout/stderr capture | No — artifact only | None needed | No | Cosmetic |

### Observations

**The fundamental gap** is that multi-file TR writes (W1) are per-file
atomic but not batch-atomic. The system relies on git rollback in finalize
to achieve batch-level recovery, but finalize is a separate step that
runs later. Between TR writes and finalize rollback, there is no crash
protection.

The only way to achieve true crash-atomic batch writes would be one of:
- Write to a staging area (temp directory), then atomically swap into the
  repo (complex; breaks git assumptions)
- Use git's own staging mechanism (`git add` + `git stash` or similar) to
  hold writes until commit
- Accept the current design and document W1/W2 as known risks mitigated
  by the preflight `is_clean` check (which prevents a dirty repo from
  being used for the next run)

**The preflight `is_clean` check is the critical safety net.** It does not
prevent W1/W2, but it prevents a subsequent run from executing against a
corrupted repo. The failure mode is liveness (the next run is blocked
until manual cleanup) rather than silent corruption.

**There is no write-ahead log.** The system cannot distinguish "process
crashed during TR writes" from "user made manual edits." Both produce the
same `is_clean=False` preflight failure. A WAL or transaction marker would
enable automatic recovery, but the current design does not include one.
