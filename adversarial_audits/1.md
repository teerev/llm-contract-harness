# Factory Idempotency & Redundancy Audit

Diagnosis of the factory execution path for re-execution, no-op detection,
and deterministic-failure retry behavior. Based on direct inspection of all
production code in `factory/`.

---

## 1. Can the same work order be executed twice?

**Short answer:** Yes, but the system has no mechanism to detect or
short-circuit already-completed work. The outcome depends on the work
order's preconditions.

### Scenario A: Work order has `file_absent` preconditions

If WO-01 declares `preconditions: [{"kind": "file_absent", "path": "scripts/verify.sh"}]`
and is run a second time after the first run created that file, the
precondition gate in `se_node` (line 192) catches it immediately:

```
elif cond.kind == "file_absent" and os.path.isfile(abs_path):
    fb = FailureBrief(stage="preflight", ...)
```

**However:** This produces a `FailureBrief` with `stage="preflight"`, which
flows through to finalize. Finalize records a FAIL verdict and — critically
— routes back to SE for retry (`_route_after_finalize`, `graph.py:76-78`).
The retry hits the same precondition gate and fails identically. This
repeats for every remaining attempt.

**Result:** `max_attempts` identical preflight failures, each recorded as a
separate attempt in `run_summary.json`. No LLM calls are made, but the
retry loop is fully exercised. The final verdict is FAIL.

### Scenario B: Work order has only `file_exists` preconditions (or none)

The precondition gate passes. The SE node proceeds to:

1. Read context files — which now contain the **already-implemented** code
   from the first run (`nodes_se.py:30-64`).
2. Build a prompt showing the LLM these already-correct files with their
   SHA-256 hashes (`nodes_se.py:106-119`).
3. Call the LLM (`nodes_se.py:233`).

The LLM sees working code and an instruction to "implement the requested
changes." It has no signal that the work is done. The prompt
(`FACTORY_PROMPT.md`) does not mention idempotency or the possibility that
no changes are needed.

The LLM must produce a `WriteProposal` with at least one write
(`schemas.py:155-157` — `_writes_non_empty` rejects an empty list). Even
if the LLM "knows" the work is done, it cannot express "no changes needed."
It must write something.

**Result:** Unnecessary LLM call, unnecessary file writes (likely
identical content, but not guaranteed), unnecessary verify + acceptance
execution. If the LLM produces different-but-valid code, the repo content
diverges from the first run. If it produces broken code, the run fails and
retries, potentially consuming all attempts on work that was already correct.

---

## 2. Specific Issues

### Issue 1: Preflight failures are retried despite being deterministic

**Location:** `factory/graph.py::_route_after_finalize` (lines 72-78),
`factory/nodes_se.py::se_node` (lines 164-213)

**Mechanism:** When a precondition fails (e.g., `file_absent` on a file
that exists), `se_node` returns a `FailureBrief(stage="preflight")`.
The finalize node records the attempt as FAIL and increments
`attempt_index`. `_route_after_finalize` then checks:

```python
if state.get("verdict") == "PASS":
    return END
if state["attempt_index"] > state["max_attempts"]:
    return END
return "se"      # ← retries unconditionally
```

There is no check for whether the failure is retryable. Preflight
failures are plan-level errors that cannot be fixed by the executor
LLM. The routing logic does not distinguish them from LLM errors.

**Failure mode:** With `max_attempts=5`, a single precondition violation
produces 5 identical failure records, 5 identical artifact sets, and 5
rollback operations (each a no-op since no writes were applied). The
`failure_brief.constraints_reminder` even says *"This is a plan-level
error. The work order sequence is invalid. Re-run the planner."* — yet
the system retries anyway.

**Severity:** Operational. No data loss or correctness issue, but wastes
time and produces misleading artifact counts (`total_attempts: 5` suggests
the system tried hard, when in fact the failure was predetermined).

### Issue 2: No postcondition-satisfaction short-circuit

**Location:** `factory/nodes_se.py::se_node` (lines 152-278),
`factory/nodes_po.py::po_node` (lines 117-143)

**Mechanism:** The PO node checks postconditions *after* TR writes
(lines 121-143). These are the same conditions that would indicate "work
is already done" if checked *before* the LLM call. No code path checks
postconditions before invoking the SE LLM.

**Failure mode:** If all postconditions are already satisfied (every
`file_exists` postcondition path already exists with correct content),
the system still calls the LLM, writes files, runs verify, and runs
acceptance. The entire pipeline executes with no possibility of
short-circuiting.

**Severity:** Operational. Wastes an LLM API call (cost + latency),
performs unnecessary file I/O, and risks semantic regression if the LLM
produces different content than what already exists.

### Issue 3: No content-diff check before writes

**Location:** `factory/nodes_tr.py::tr_node` (lines 166-181)

**Mechanism:** TR applies every write in the proposal unconditionally.
It validates scope and base-hash, then calls `_atomic_write` for each
file. There is no comparison between the proposed content and the
existing content.

```python
for w in proposal.writes:
    norm = normalize_path(w.path)
    abs_path = os.path.join(repo_root, norm)
    try:
        _atomic_write(abs_path, w.content)
```

**Failure mode:** If the LLM proposes writing the identical content that
already exists on disk (the likely outcome when re-executing a completed
work order), the file is still opened, written to a temp file, fsynced,
and atomically replaced. The file's mtime changes even though the content
is byte-identical. The `touched_files` list includes these files, and
`get_tree_hash` stages them — though git will recognize no content change.

**Severity:** Cosmetic. No data loss. The git tree hash will be the same
(git operates on content, not mtimes). But the artifact trail is
misleading: `write_result.json` reports `write_ok: true` with files
"touched" that were not actually changed.

### Issue 4: WriteProposal schema forbids empty writes

**Location:** `factory/schemas.py::WriteProposal._writes_non_empty`
(lines 153-157)

**Mechanism:** The Pydantic validator rejects `writes: []`:

```python
@field_validator("writes", mode="before")
@classmethod
def _writes_non_empty(cls, v: list) -> list:
    if not v:
        raise ValueError("writes must be non-empty")
    return v
```

**Failure mode:** Even if the LLM correctly determines that no changes
are needed, it cannot express this. The only valid response is a
`WriteProposal` with at least one `FileWrite`. The LLM is forced to
produce a write — typically rewriting an existing file to its current
content, or producing a subtly different implementation.

This is not a schema bug per se (the factory's design assumes every work
order requires writes), but it makes idempotent re-execution structurally
impossible at the protocol level.

**Severity:** Correctness (architectural). The system cannot represent
"nothing to do" in its contract format. This forces unnecessary writes and
creates a semantic regression risk: the LLM may produce a functionally
different implementation on the second pass.

### Issue 5: No detection of duplicate run_id

**Location:** `factory/run.py::run_cli` (lines 64-67)

**Mechanism:** The `run_id` is computed as
`sha256(canonical_json(work_order) + baseline_commit)[:16]`. If the same
work order is re-executed on the same baseline commit (before the first
run's changes are committed), the run_id is identical:

```python
run_id = compute_run_id(work_order.model_dump(), baseline_commit)
run_dir = os.path.join(out_dir, run_id)
os.makedirs(run_dir, exist_ok=True)
```

The `exist_ok=True` means the directory already exists from the first
run. The new run's `work_order.json` and `run_summary.json` silently
overwrite the first run's artifacts (via `save_json` which uses atomic
`os.replace`).

**Failure mode:** If the first run PASSed and the second run FAILs, the
PASS summary is overwritten with a FAIL summary. The first run's evidence
is lost. Per-attempt artifacts use `attempt_1/`, `attempt_2/` etc., so
they may also collide with the first run's attempt directories.

**Severity:** Operational / data-loss. Previous run artifacts are silently
destroyed. This is the most practically damaging issue in a re-execution
scenario because it eliminates the audit trail of the successful run.

Note: in the batch execution path (`run_work_orders.sh`), the first run's
changes are committed before the second work order runs, which changes the
baseline commit and thus the run_id. So this issue primarily affects
direct `python -m factory run` invocations against the same repo state.

### Issue 6: Acceptance commands re-executed after already-proven state

**Location:** `factory/nodes_po.py::po_node` (lines 148-199)

**Mechanism:** Acceptance commands run unconditionally in the PO node.
There is no check for whether the acceptance commands have already passed
on the current repo state.

**Failure mode:** On a re-execution where the LLM writes identical
content, verify and acceptance are re-run unnecessarily. These may involve
`python -m pytest -q` (the full test suite), which can take significant
time. More critically, acceptance commands with side effects (writing temp
files, modifying state) execute again — though in practice the current
command patterns are read-only assertions.

**Severity:** Operational. Cost is proportional to acceptance command
runtime. No correctness issue unless acceptance commands have side effects.

---

## 3. Summary Table

| # | Issue | Location | Failure mode | Severity |
|---|-------|----------|--------------|----------|
| 1 | Preflight failures retried | `graph.py:72-78`, `nodes_se.py:164-213` | Deterministic failure repeated `max_attempts` times | Operational |
| 2 | No postcondition short-circuit | `nodes_se.py:152+`, `nodes_po.py:117-143` | LLM called when work is already done | Operational |
| 3 | No content-diff before write | `nodes_tr.py:166-181` | Identical files rewritten; misleading artifacts | Cosmetic |
| 4 | Schema forbids empty writes | `schemas.py:153-157` | LLM cannot express "nothing to do" | Correctness (architectural) |
| 5 | Duplicate run_id overwrites artifacts | `run.py:64-67` | Prior run's summary + artifacts silently destroyed | Data-loss |
| 6 | Acceptance re-run on proven state | `nodes_po.py:148-199` | Unnecessary command execution after no-op writes | Operational |

Issues 1–4 are interconnected: the system has no concept of "already
satisfied" at any layer — not in the routing logic (issue 1), not before
the LLM call (issue 2), not in the write path (issue 3), and not in the
contract schema (issue 4). A single idempotency check at the right layer
would address multiple issues simultaneously, but the choice of *which*
layer and *what* check is a design decision, not an implementation fix.

Issue 5 is independent and has the most immediate practical impact
(artifact destruction).
